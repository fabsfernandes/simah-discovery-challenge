{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[SIMAH ECML PKDD 2019]Fabiola_Thiago_Andre.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XMau7VZPv1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XayWPa3plA07",
        "colab_type": "text"
      },
      "source": [
        "# Final Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eBVRo6CmKkg",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from joblib import dump, load\n",
        "pd.set_option('max_colwidth', 160)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#warnings.filterwarnings(action='once')\n",
        "\n",
        "data_train = pd.read_csv('Train_data_compeition.csv')\n",
        "data_validation = pd.read_csv('Validation_data_competition.csv')\n",
        "data_finaltest = pd.read_csv('testdata_gold_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufAEvobGmriM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature engineering\n",
        "data_train['total_words'] = data_train.apply(lambda x: len(x['tweet_content'].split()), axis=1)\n",
        "data_validation['total_words'] = data_validation.apply(lambda x: len(x['tweet_content'].split()), axis=1)\n",
        "data_finaltest['total_words'] = data_finaltest.apply(lambda x: len(x['tweet_content'].split()), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bmp3azumv2s",
        "colab_type": "code",
        "outputId": "1cf3e760-e935-46f1-d0f5-0868ae243143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# text pipeline\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report, confusion_matrix, roc_auc_score, recall_score\n",
        "\n",
        "class TextSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, field):\n",
        "        self.field = field\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.field]\n",
        "      \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, field):\n",
        "        self.field = field\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[[self.field]]\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def Tokenizer__(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    porter_stemmer=nltk.PorterStemmer()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words\n",
        "  \n",
        "\n",
        "#stop_words = set(stopwords.words('english'))\n",
        "stop_words = stopwords.words('english')\n",
        "#stop_words = stop_words.extend(['RT'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnQx0rptlkp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_results(y_test, preds):\n",
        "  acc = \"Accuracy: \" + str(accuracy_score(y_test, preds))\n",
        "  precision = \"Precision: \" + str(precision_score(y_test, preds))\n",
        "  f1 = \"F1 Score: \" + str(f1_score(y_test, preds))\n",
        "  roc_auc = \"ROC AUC:\" + str(roc_auc_score(y_test, preds))\n",
        "  report = str(classification_report(y_test, preds))\n",
        "  conf_matrix = str(confusion_matrix(y_test, preds))\n",
        "  #results = acc + '\\n' + precision + '\\n' + f1 + '\\n' + roc_auc + '\\n' + report + '\\n' + conf_matrix\n",
        "  results = acc + '\\n' + precision + '\\n' + f1 + '\\n' + roc_auc\n",
        "  print(results, '\\n')\n",
        "\n",
        "def print_cv_results(cv_results):\n",
        "  for key in cv_results:\n",
        "    score = key\n",
        "    value = np.mean(cv_results[key])\n",
        "    print(score + \": \", value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbPqJTFAlK6P",
        "colab_type": "text"
      },
      "source": [
        "## Task A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpwapQZ7S0hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = data_train[['tweet_content','total_words']]\n",
        "#Y = data_train['harassment']\n",
        "\n",
        "data_all = data_train.append(data_validation)\n",
        "X = data_all[['tweet_content','total_words']]\n",
        "Y = data_all['harassment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7H_g1i2lSt3",
        "colab_type": "text"
      },
      "source": [
        "### Approach 1: RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8DrfA8YLtaa",
        "colab_type": "code",
        "outputId": "96ab5a74-18b7-4c39-b094-747ec3b9dae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=5, max_df=0.9, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
        "        ])),\n",
        "        ('words', Pipeline([\n",
        "            ('wordext', NumberSelector('total_words')),\n",
        "            ('wscaler', StandardScaler()),\n",
        "        ])),\n",
        "    ])),\n",
        "     ('clf', RandomForestClassifier()),\n",
        "    ])\n",
        "\n",
        "classifier.fit(X, Y)\n",
        "dump(classifier, 'taskA_RF.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskA_RF.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yty9SyIClW9c",
        "colab_type": "text"
      },
      "source": [
        "### Approach 2: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8K7Luctleg1",
        "colab_type": "code",
        "outputId": "a734ce7c-fdaa-4daf-9e16-762f387d8c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=5, max_df=0.9, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
        "        ])),\n",
        "        ('words', Pipeline([\n",
        "            ('wordext', NumberSelector('total_words')),\n",
        "            ('wscaler', StandardScaler()),\n",
        "        ])),\n",
        "    ])),\n",
        "    ('clf', \n",
        "     XGBClassifier(max_depth=2, n_estimators=300, learning_rate=0.1)\n",
        "     ),\n",
        "    ])\n",
        "classifier.fit(X, Y)\n",
        "dump(classifier, 'taskA_XGBoost.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskA_XGBoost.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg3eeRjHXp40",
        "colab_type": "text"
      },
      "source": [
        "### Approach 3: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXe-7ZWlXqr2",
        "colab_type": "code",
        "outputId": "01084046-50b2-43ae-d499-f62c3605604a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "MAX_NB_WORDS = 5000\n",
        "MAX_SEQUENCE_LENGTH = 15\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizerLSTM = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizerLSTM.fit_on_texts(data_all['tweet_content'].values)\n",
        "word_index = tokenizerLSTM.word_index\n",
        "\n",
        "X = tokenizerLSTM.texts_to_sequences(data_all['tweet_content'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "Y = pd.get_dummies(data_all['harassment']).values\n",
        "\n",
        "X_val = tokenizerLSTM.texts_to_sequences(data_validation['tweet_content'].values)\n",
        "X_val = pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "Y_val = pd.get_dummies(data_validation['harassment']).values\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "#history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_data=(X_val, Y_val),callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "dump(model, 'taskA_LSTM.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8499 samples, validate on 2125 samples\n",
            "Epoch 1/50\n",
            "8499/8499 [==============================] - 19s 2ms/step - loss: 0.4456 - acc: 0.7941 - val_loss: 0.2379 - val_acc: 0.9129\n",
            "Epoch 2/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.2713 - acc: 0.8955 - val_loss: 0.1998 - val_acc: 0.9360\n",
            "Epoch 3/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.2320 - acc: 0.9112 - val_loss: 0.1731 - val_acc: 0.9435\n",
            "Epoch 4/50\n",
            "8499/8499 [==============================] - 11s 1ms/step - loss: 0.2025 - acc: 0.9229 - val_loss: 0.1386 - val_acc: 0.9576\n",
            "Epoch 5/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.1733 - acc: 0.9332 - val_loss: 0.1004 - val_acc: 0.9704\n",
            "Epoch 6/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.1590 - acc: 0.9418 - val_loss: 0.0872 - val_acc: 0.9671\n",
            "Epoch 7/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.1322 - acc: 0.9512 - val_loss: 0.0662 - val_acc: 0.9788\n",
            "Epoch 8/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.1177 - acc: 0.9526 - val_loss: 0.0598 - val_acc: 0.9835\n",
            "Epoch 9/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.1042 - acc: 0.9606 - val_loss: 0.0639 - val_acc: 0.9816\n",
            "Epoch 10/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0918 - acc: 0.9666 - val_loss: 0.0393 - val_acc: 0.9896\n",
            "Epoch 11/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0773 - acc: 0.9734 - val_loss: 0.0369 - val_acc: 0.9882\n",
            "Epoch 12/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0697 - acc: 0.9740 - val_loss: 0.0290 - val_acc: 0.9901\n",
            "Epoch 13/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0706 - acc: 0.9723 - val_loss: 0.0361 - val_acc: 0.9901\n",
            "Epoch 14/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0731 - acc: 0.9713 - val_loss: 0.0454 - val_acc: 0.9873\n",
            "Epoch 15/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0623 - acc: 0.9749 - val_loss: 0.0241 - val_acc: 0.9944\n",
            "Epoch 16/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0524 - acc: 0.9794 - val_loss: 0.0187 - val_acc: 0.9953\n",
            "Epoch 17/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0486 - acc: 0.9808 - val_loss: 0.0217 - val_acc: 0.9934\n",
            "Epoch 18/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0439 - acc: 0.9828 - val_loss: 0.0165 - val_acc: 0.9939\n",
            "Epoch 19/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0420 - acc: 0.9834 - val_loss: 0.0180 - val_acc: 0.9939\n",
            "Epoch 20/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0403 - acc: 0.9839 - val_loss: 0.0202 - val_acc: 0.9925\n",
            "Epoch 21/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0445 - acc: 0.9825 - val_loss: 0.0162 - val_acc: 0.9944\n",
            "Epoch 22/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0366 - acc: 0.9854 - val_loss: 0.0167 - val_acc: 0.9953\n",
            "Epoch 23/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0413 - acc: 0.9829 - val_loss: 0.0162 - val_acc: 0.9939\n",
            "Epoch 24/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0375 - acc: 0.9847 - val_loss: 0.0130 - val_acc: 0.9958\n",
            "Epoch 25/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0364 - acc: 0.9845 - val_loss: 0.0204 - val_acc: 0.9944\n",
            "Epoch 26/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0365 - acc: 0.9846 - val_loss: 0.0113 - val_acc: 0.9958\n",
            "Epoch 27/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0327 - acc: 0.9851 - val_loss: 0.0112 - val_acc: 0.9953\n",
            "Epoch 28/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0420 - acc: 0.9833 - val_loss: 0.0107 - val_acc: 0.9953\n",
            "Epoch 29/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0286 - acc: 0.9880 - val_loss: 0.0111 - val_acc: 0.9953\n",
            "Epoch 30/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0296 - acc: 0.9852 - val_loss: 0.0094 - val_acc: 0.9967\n",
            "Epoch 31/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0310 - acc: 0.9864 - val_loss: 0.0141 - val_acc: 0.9948\n",
            "Epoch 32/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0340 - acc: 0.9846 - val_loss: 0.0117 - val_acc: 0.9953\n",
            "Epoch 33/50\n",
            "8499/8499 [==============================] - 10s 1ms/step - loss: 0.0313 - acc: 0.9859 - val_loss: 0.0123 - val_acc: 0.9944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskA_LSTM.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuXN24MoTFtR",
        "colab_type": "text"
      },
      "source": [
        "### Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liGPfMRCTWtP",
        "colab_type": "text"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHBdK2wTP-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_validation[['tweet_content','total_words']]\n",
        "Y = data_validation['harassment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kvQLnVdTfCC",
        "colab_type": "code",
        "outputId": "ac538814-7138-4248-b7e7-e34831c3147b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Approach 1: RF\n",
        "approach = 'taskA_RF'\n",
        "print(approach, 'validation')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "preds = model.predict(X)\n",
        "print_results(Y,preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskA_RF validation\n",
            "============\n",
            "Accuracy: 0.9854117647058823\n",
            "Precision: 0.993431855500821\n",
            "F1 Score: 0.9750201450443191\n",
            "ROC AUC:0.977299655777595 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssuGsal5T9-m",
        "colab_type": "code",
        "outputId": "c1e3d180-6215-4519-f931-03d24bf8d5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Approach 2: XGBoost\n",
        "approach = 'taskA_XGBoost'\n",
        "print(approach, 'validation')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "preds = model.predict(X)\n",
        "print_results(Y,preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskA_XGBoost validation\n",
            "============\n",
            "Accuracy: 0.9228235294117647\n",
            "Precision: 0.9020618556701031\n",
            "F1 Score: 0.8649093904448105\n",
            "ROC AUC:0.896259018881362 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qtF6hDVZPyR",
        "colab_type": "code",
        "outputId": "a5d5012f-c0ef-4ae4-bf9a-64b61c8dd1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Approach 3: LSTM\n",
        "approach = 'taskA_LSTM'\n",
        "print(approach, 'validation')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "X = tokenizerLSTM.texts_to_sequences(data_validation['tweet_content'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "preds = model.predict(X, batch_size=64, verbose=1)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "preds_final = []\n",
        "for pred in preds:\n",
        "  preds_final.append(pred)\n",
        "Y = pd.get_dummies(data_validation['harassment'])\n",
        "Y = Y.idxmax(axis=1)\n",
        "Y_final = []\n",
        "for y_real in Y:\n",
        "  Y_final.append(y_real)\n",
        "print_results(Y_final,preds_final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskA_LSTM validation\n",
            "============\n",
            "2125/2125 [==============================] - 4s 2ms/step\n",
            "Accuracy: 0.9943529411764706\n",
            "Precision: 0.990506329113924\n",
            "F1 Score: 0.990506329113924\n",
            "ROC AUC:0.9932437874638609 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ60sQF4UKoR",
        "colab_type": "text"
      },
      "source": [
        "#### Test Final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZBgYYD6UOCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_finaltest[['tweet_content','total_words']]\n",
        "Y = data_finaltest['harassment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LumkLNu3UOxU",
        "colab_type": "code",
        "outputId": "690b8c00-1063-4576-d3b0-3cc14bec44b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Approach 1: RF\n",
        "approach = 'taskA_RF'\n",
        "print(approach, 'test final')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "preds = model.predict(X)\n",
        "print_results(Y,preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskA_RF test final\n",
            "============\n",
            "Accuracy: 0.7974564295807819\n",
            "Precision: 0.7986798679867987\n",
            "F1 Score: 0.5295404814004376\n",
            "ROC AUC:0.6778640488746872 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgpcavOIUP9n",
        "colab_type": "code",
        "outputId": "246e2206-ebb7-4218-8869-94a2fb49766e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Approach 2: XGBoost\n",
        "approach = 'taskA_XGBoost'\n",
        "print(approach, 'test final')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "preds = model.predict(X)\n",
        "print_results(Y,preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskA_XGBoost test final\n",
            "============\n",
            "Accuracy: 0.8191238813000471\n",
            "Precision: 0.814404432132964\n",
            "F1 Score: 0.6049382716049382\n",
            "ROC AUC:0.7184331133799219 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgMJKMHWZ5XM",
        "colab_type": "code",
        "outputId": "a4b38906-2546-4cca-de68-bb462abf1776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Approach 3: LSTM\n",
        "approach = 'taskA_LSTM'\n",
        "print(approach, 'test final')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "X = tokenizerLSTM.texts_to_sequences(data_finaltest['tweet_content'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "preds = model.predict(X, batch_size=64, verbose=1)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "preds_final = []\n",
        "for pred in preds:\n",
        "  preds_final.append(pred)\n",
        "Y = pd.get_dummies(data_finaltest['harassment'])\n",
        "Y = Y.idxmax(axis=1)\n",
        "Y_final = []\n",
        "for y_real in Y:\n",
        "  Y_final.append(y_real)\n",
        "print_results(Y_final,preds_final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskA_LSTM test final\n",
            "============\n",
            "2123/2123 [==============================] - 4s 2ms/step\n",
            "Accuracy: 0.7644842204427696\n",
            "Precision: 0.6305882352941177\n",
            "F1 Score: 0.5173745173745173\n",
            "ROC AUC:0.6673946128733362 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRk_GlnRjh1S",
        "colab_type": "code",
        "outputId": "a1a0f508-a8ce-4c53-aa32-38e4399d7b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Approach 2.submitted: XGBoost\n",
        "def Tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    porter_stemmer=nltk.PorterStemmer()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words\n",
        "  \n",
        "X = data_finaltest[['tweet_content','total_words']]\n",
        "Y = data_finaltest['harassment']\n",
        "approach = 'harass-xgboost-train'\n",
        "print(approach, 'test final')\n",
        "print('============')\n",
        "model = load(approach + '.joblib')\n",
        "preds = model.predict(X)\n",
        "print_results(Y,preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "harass-xgboost-train test final\n",
            "============\n",
            "Accuracy: 0.8082901554404145\n",
            "Precision: 0.788135593220339\n",
            "F1 Score: 0.5782383419689119\n",
            "ROC AUC:0.7035126516509494 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCAd09gPgN8t",
        "colab_type": "text"
      },
      "source": [
        "## Task B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmAwEghZhsPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9SQcI2GhYcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_type(x):\n",
        "  if x[3] == 1:\n",
        "    return 1\n",
        "  if x[4] == 1:\n",
        "    return 2\n",
        "  if x[5] == 1:\n",
        "    return 3\n",
        "  return 0\n",
        "\n",
        "data_train['harassment-type'] = data_train.apply(get_type, axis=1)\n",
        "data_validation['harassment-type'] = data_validation.apply(get_type, axis=1)\n",
        "data_finaltest['harassment-type'] = data_finaltest.apply(get_type, axis=1)\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words = stop_words.extend(['RT'])\n",
        "\n",
        "def print_results_multiclass(y_test, preds):\n",
        "  print('True labels:', y_test)\n",
        "  print('Pred labels:', preds)\n",
        "  acc = \"Accuracy: \" + str(accuracy_score(y_test, preds))\n",
        "  precision = \"Precision: \" + str(precision_score(y_test, preds, average='macro'))\n",
        "  recall = \"Recall: \" + str(recall_score(y_test, preds, average='macro'))\n",
        "  #f1 = \"F1 Score: \" + str(f1_score(y_test, preds))\n",
        "  #roc_auc = \"ROC AUC:\" + str(roc_auc_score(y_test, preds, average='macro'))\n",
        "  f1_macro = \"F1 Macro-avg:\" + str(f1_score(y_test, preds, average='macro'))\n",
        "  report = str(classification_report(y_test, preds))\n",
        "  conf_matrix = str(confusion_matrix(y_test, preds))\n",
        "  #results = acc + '\\n' + precision + '\\n' + f1 + '\\n' + roc_auc + '\\n' + report + '\\n' + conf_matrix\n",
        "  results = acc + '\\n' + precision + '\\n' + recall + '\\n' + f1_macro\n",
        "  print(results, '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vLRFkHqWohr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_train_harassment = data_train[data_train['harassment'] == 1]\n",
        "data_all = data_train.append(data_validation)\n",
        "data_train_harassment = data_all[data_all['harassment'] == 1]\n",
        "\n",
        "X = data_train_harassment[['tweet_content','total_words']]\n",
        "Y = data_train_harassment['harassment-type']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guIABdaugf93",
        "colab_type": "text"
      },
      "source": [
        "### Approach 1: OORF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_FKe-PAeNXg",
        "colab_type": "code",
        "outputId": "838fd7bd-b8f2-4bb2-b7a7-248a0b42a25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
        "        ])),\n",
        "        ('words', Pipeline([\n",
        "            ('wordext', NumberSelector('total_words')),\n",
        "            ('wscaler', StandardScaler()),\n",
        "        ])),\n",
        "    ])),\n",
        "    ('clf', OneVsOneClassifier(RandomForestClassifier())),\n",
        "    ])\n",
        "classifier.fit(X, Y)\n",
        "dump(classifier, 'taskB_OORF.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskB_OORF.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8eYLQXcgWvM",
        "colab_type": "text"
      },
      "source": [
        "### Approach 2: OCRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aaSAZiKgbAA",
        "colab_type": "code",
        "outputId": "3b01e1a8-4308-475b-f5a0-182889cd3463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
        "        ])),\n",
        "        ('words', Pipeline([\n",
        "            ('wordext', NumberSelector('total_words')),\n",
        "            ('wscaler', StandardScaler()),\n",
        "        ])),\n",
        "    ])),\n",
        "    ('clf', OutputCodeClassifier(RandomForestClassifier(), code_size=2, random_state=0)),\n",
        "    ])\n",
        "classifier.fit(X, Y)\n",
        "dump(classifier, 'taskB_OCRF.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskB_OCRF.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWG5pevKglwT",
        "colab_type": "text"
      },
      "source": [
        "### Approach 3: OCGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3AzWXORgouN",
        "colab_type": "code",
        "outputId": "c84ab5cd-8d48-41d1-dae2-9c239c0aad02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=5, max_df=0.9, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=250)), #for XGB\n",
        "        ])),\n",
        "        ('text2', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=5, max_df=0.9, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
        "        ])),\n",
        "        \n",
        "    #    ('words', Pipeline([\n",
        "    #        ('wordext', NumberSelector('total_words')),\n",
        "    #        ('wscaler', StandardScaler()),\n",
        "    #    ])),\n",
        "    ])),\n",
        "    #('clf', OneVsOneClassifier(\n",
        "        #ExtraTreesClassifier(n_estimators=200, max_depth=None,min_samples_split=3, random_state=0)\n",
        "        #AdaBoostClassifier(DecisionTreeClassifier(max_depth=None), algorithm=\"SAMME\", n_estimators=5)\n",
        "    #    GradientBoostingClassifier(n_estimators=20, learning_rate=1.0,max_depth=7, random_state=14)\n",
        "        #XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
        "    #    )),\n",
        "    ('clf', OutputCodeClassifier(\n",
        "        GradientBoostingClassifier(n_estimators=20, learning_rate=1.0,max_depth=7, random_state=14),\n",
        "        code_size=15, random_state=0)\n",
        "    )\n",
        "    \n",
        "    ])\n",
        "classifier.fit(X, Y)\n",
        "dump(classifier, 'taskB_OCGB.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskB_OCGB.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STZGjR9Agqia",
        "colab_type": "text"
      },
      "source": [
        "### Approach 4: OOCB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQX-u3uQguTx",
        "colab_type": "code",
        "outputId": "63251a1c-ae7a-4e79-bc4d-a230d338e08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "classifier = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', Pipeline([\n",
        "            ('colext', TextSelector('tweet_content')),\n",
        "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer__, stop_words=stop_words,\n",
        "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
        "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
        "        ])),\n",
        "        ('words', Pipeline([\n",
        "            ('wordext', NumberSelector('total_words')),\n",
        "            ('wscaler', StandardScaler()),\n",
        "        ])),\n",
        "    ])),\n",
        "    ('clf', OneVsOneClassifier(CatBoostClassifier(iterations=5,\n",
        "                           depth=10,\n",
        "                           learning_rate=1,\n",
        "                           loss_function='Logloss',\n",
        "                           verbose=True))),\n",
        "    ])\n",
        "classifier.fit(X, Y)\n",
        "dump(classifier, 'taskB_OOCB.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.16.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (3.6.1)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.24.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.16.4)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (4.4.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (4.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (2018.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (4.3.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (4.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (2.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.2.0)\n",
            "0:\tlearn: 0.4003370\ttotal: 815ms\tremaining: 3.26s\n",
            "1:\tlearn: 0.2165603\ttotal: 1.64s\tremaining: 2.46s\n",
            "2:\tlearn: 0.1409314\ttotal: 2.45s\tremaining: 1.63s\n",
            "3:\tlearn: 0.0994242\ttotal: 3.26s\tremaining: 816ms\n",
            "4:\tlearn: 0.0788926\ttotal: 4.08s\tremaining: 0us\n",
            "0:\tlearn: 0.1506976\ttotal: 906ms\tremaining: 3.62s\n",
            "1:\tlearn: 0.1134568\ttotal: 1.81s\tremaining: 2.71s\n",
            "2:\tlearn: 0.0957433\ttotal: 2.71s\tremaining: 1.81s\n",
            "3:\tlearn: 0.0808850\ttotal: 3.62s\tremaining: 904ms\n",
            "4:\tlearn: 0.0642638\ttotal: 4.53s\tremaining: 0us\n",
            "0:\tlearn: 0.1513744\ttotal: 910ms\tremaining: 3.64s\n",
            "1:\tlearn: 0.1253973\ttotal: 1.82s\tremaining: 2.72s\n",
            "2:\tlearn: 0.1091040\ttotal: 2.73s\tremaining: 1.82s\n",
            "3:\tlearn: 0.0947542\ttotal: 3.63s\tremaining: 908ms\n",
            "4:\tlearn: 0.0825960\ttotal: 4.54s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskB_OOCB.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrMUkGl_gu2w",
        "colab_type": "text"
      },
      "source": [
        "### Approach 5: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conYLxaLgwaq",
        "colab_type": "code",
        "outputId": "17f77d11-bf02-49f4-f3d2-c14cf16e160e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "MAX_NB_WORDS = 5000\n",
        "MAX_SEQUENCE_LENGTH = 15\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizerLSTM = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizerLSTM.fit_on_texts(data_train_harassment['tweet_content'].values)\n",
        "word_index = tokenizerLSTM.word_index\n",
        "\n",
        "X = tokenizerLSTM.texts_to_sequences(data_train_harassment['tweet_content'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "Y = pd.get_dummies(data_train_harassment['harassment-type']).values\n",
        "\n",
        "X_val = tokenizerLSTM.texts_to_sequences(data_validation_harassment['tweet_content'].values)\n",
        "X_val = pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "Y_val = pd.get_dummies(data_validation_harassment['harassment-type']).values\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "#history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_data=(X_val, Y_val),callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "dump(model, 'taskB_LSTM.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3345 samples, validate on 632 samples\n",
            "Epoch 1/50\n",
            "3345/3345 [==============================] - 14s 4ms/step - loss: 0.4388 - acc: 0.9166 - val_loss: 0.5271 - val_acc: 0.8307\n",
            "Epoch 2/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.2474 - acc: 0.9286 - val_loss: 0.3288 - val_acc: 0.8449\n",
            "Epoch 3/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.1748 - acc: 0.9405 - val_loss: 0.2407 - val_acc: 0.9019\n",
            "Epoch 4/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.1357 - acc: 0.9504 - val_loss: 0.2000 - val_acc: 0.9304\n",
            "Epoch 5/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.1103 - acc: 0.9552 - val_loss: 0.1681 - val_acc: 0.9383\n",
            "Epoch 6/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0942 - acc: 0.9617 - val_loss: 0.1417 - val_acc: 0.9589\n",
            "Epoch 7/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0790 - acc: 0.9698 - val_loss: 0.1466 - val_acc: 0.9620\n",
            "Epoch 8/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0657 - acc: 0.9794 - val_loss: 0.0803 - val_acc: 0.9810\n",
            "Epoch 9/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0512 - acc: 0.9857 - val_loss: 0.0538 - val_acc: 0.9794\n",
            "Epoch 10/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0375 - acc: 0.9880 - val_loss: 0.0425 - val_acc: 0.9937\n",
            "Epoch 11/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0380 - acc: 0.9895 - val_loss: 0.0287 - val_acc: 0.9968\n",
            "Epoch 12/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0264 - acc: 0.9925 - val_loss: 0.0243 - val_acc: 0.9984\n",
            "Epoch 13/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0231 - acc: 0.9934 - val_loss: 0.0190 - val_acc: 0.9921\n",
            "Epoch 14/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0251 - acc: 0.9931 - val_loss: 0.0178 - val_acc: 0.9968\n",
            "Epoch 15/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0195 - acc: 0.9928 - val_loss: 0.0169 - val_acc: 0.9968\n",
            "Epoch 16/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.0159 - val_acc: 0.9968\n",
            "Epoch 17/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0169 - acc: 0.9922 - val_loss: 0.0139 - val_acc: 0.9937\n",
            "Epoch 18/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0135 - val_acc: 0.9968\n",
            "Epoch 19/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0159 - acc: 0.9958 - val_loss: 0.0224 - val_acc: 0.9968\n",
            "Epoch 20/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0191 - acc: 0.9949 - val_loss: 0.0156 - val_acc: 0.9953\n",
            "Epoch 21/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0060 - val_acc: 0.9984\n",
            "Epoch 22/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0182 - acc: 0.9943 - val_loss: 0.0062 - val_acc: 0.9984\n",
            "Epoch 23/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0100 - acc: 0.9961 - val_loss: 0.0085 - val_acc: 0.9968\n",
            "Epoch 24/50\n",
            "3345/3345 [==============================] - 4s 1ms/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0154 - val_acc: 0.9968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taskB_LSTM.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8njqT18gXrl3",
        "colab_type": "text"
      },
      "source": [
        "### Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKCjGLqJcn3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "approaches = ['taskB_OORF', 'taskB_OCRF', 'taskB_OCGB', 'taskB_OOCB', 'multi-outputcode-gradientboost-all']\n",
        "\n",
        "def Tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    porter_stemmer=nltk.PorterStemmer()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hydJ5w1JXvoe",
        "colab_type": "text"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Vr5-KrX0Hm",
        "colab_type": "code",
        "outputId": "f08fbcb5-735e-4efe-c76e-7247bbf183c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_validation_harassment = data_validation[data_validation['harassment'] == 1]\n",
        "X = data_validation_harassment[['tweet_content','total_words']]\n",
        "Y = data_validation_harassment['harassment-type']\n",
        "\n",
        "for approach in approaches:\n",
        "  print(approach, 'validation')\n",
        "  print('============')\n",
        "  model = load(approach + '.joblib')\n",
        "  preds = model.predict(X)\n",
        "  preds_final = []\n",
        "  for pred in preds:\n",
        "    preds_final.append(pred)\n",
        "  Y_final = []\n",
        "  for y_real in Y:\n",
        "    Y_final.append(y_real)\n",
        "  print_results_multiclass(Y_final,preds_final)\n",
        "  print()\n",
        "\n",
        "\n",
        "print('taskB_LSTM', 'validation')\n",
        "print('============')\n",
        "      \n",
        "data_validation_harassment = data_validation[data_validation['harassment'] == 1]\n",
        "X = tokenizerLSTM.texts_to_sequences(data_validation_harassment['tweet_content'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "model = load('taskB_LSTM' + '.joblib')\n",
        "preds = model.predict(X, batch_size=64, verbose=1)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "preds_final = []\n",
        "for pred in preds:\n",
        "  preds_final.append(pred+1)\n",
        "Y = pd.get_dummies(data_validation_harassment['harassment-type'])\n",
        "Y = Y.idxmax(axis=1)\n",
        "Y_final = []\n",
        "for y_real in Y:\n",
        "  Y_final.append(y_real)\n",
        "print_results_multiclass(Y_final,preds_final)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskB_OORF validation\n",
            "============\n",
            "True labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Pred labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 2, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 3, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 3, 1, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3]\n",
            "Accuracy: 0.9588607594936709\n",
            "Precision: 0.984271022383545\n",
            "Recall: 0.8049034950443401\n",
            "F1 Macro-avg:0.8714548565849681 \n",
            "\n",
            "\n",
            "taskB_OCRF validation\n",
            "============\n",
            "True labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Pred labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 3, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 3, 3, 1, 1, 2, 3, 3, 3, 3, 3, 1, 2, 1, 3, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 3, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Accuracy: 0.9683544303797469\n",
            "Precision: 0.9877675840978594\n",
            "Recall: 0.8695878977569119\n",
            "F1 Macro-avg:0.921333572969087 \n",
            "\n",
            "\n",
            "taskB_OCGB validation\n",
            "============\n",
            "True labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Pred labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 2, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 3, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 2, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 2, 1, 3]\n",
            "Accuracy: 0.9604430379746836\n",
            "Precision: 0.8727058029689608\n",
            "Recall: 0.8902682763246142\n",
            "F1 Macro-avg:0.8811276025561741 \n",
            "\n",
            "\n",
            "taskB_OOCB validation\n",
            "============\n",
            "True labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Pred labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Accuracy: 0.8955696202531646\n",
            "Precision: 0.9627749576988155\n",
            "Recall: 0.55320813771518\n",
            "F1 Macro-avg:0.628983953086205 \n",
            "\n",
            "\n",
            "multi-outputcode-gradientboost-all validation\n",
            "============\n",
            "True labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Pred labels: [3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 2, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 2, 3, 1, 3, 3, 1, 2, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 2, 1, 2, 3, 1, 3, 1, 2, 1, 3, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 2, 1, 1, 3, 1, 3, 1, 3, 3, 1, 2, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 2, 1, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3]\n",
            "Accuracy: 0.9018987341772152\n",
            "Precision: 0.791784592990502\n",
            "Recall: 0.747020642372755\n",
            "F1 Macro-avg:0.7677943432541192 \n",
            "\n",
            "\n",
            "taskB_LSTM validation\n",
            "============\n",
            "632/632 [==============================] - 4s 6ms/step\n",
            "True labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Pred labels: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 1, 1, 3, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3]\n",
            "Accuracy: 0.9968354430379747\n",
            "Precision: 0.9987349778621125\n",
            "Recall: 0.9906103286384976\n",
            "F1 Macro-avg:0.9946043816766251 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ4H0CkjYW34",
        "colab_type": "text"
      },
      "source": [
        "#### Test Final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3G3sUjiYIKP",
        "colab_type": "code",
        "outputId": "f9393b18-359f-41d2-ccc0-6b771d1e52d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_finaltest_harassment = data_finaltest[data_finaltest['harassment'] == 1]\n",
        "X = data_finaltest_harassment[['tweet_content','total_words']]\n",
        "Y = data_finaltest_harassment['harassment-type']\n",
        "\n",
        "for approach in approaches:\n",
        "  print(approach, 'test final')\n",
        "  print('============')\n",
        "  model = load(approach + '.joblib')\n",
        "  preds = model.predict(X)\n",
        "  preds_final = []\n",
        "  for pred in preds:\n",
        "    preds_final.append(pred-1)\n",
        "  Y_final = []\n",
        "  for y_real in Y:\n",
        "    Y_final.append(y_real)\n",
        "  print_results_multiclass(Y_final,preds_final)\n",
        "  print()\n",
        "  \n",
        "  \n",
        "print('taskB_LSTM', 'test final')\n",
        "print('============')\n",
        "      \n",
        "data_finaltest_harassment = data_finaltest[data_finaltest['harassment'] == 1]\n",
        "X = tokenizerLSTM.texts_to_sequences(data_finaltest_harassment['tweet_content'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "model = load('taskB_LSTM' + '.joblib')\n",
        "preds = model.predict(X, batch_size=64, verbose=1)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "preds_final = []\n",
        "for pred in preds:\n",
        "  preds_final.append(pred)\n",
        "Y = pd.get_dummies(data_finaltest_harassment['harassment-type'])\n",
        "Y = Y.idxmax(axis=1)\n",
        "Y_final = []\n",
        "for y_real in Y:\n",
        "  Y_final.append(y_real)\n",
        "print_results_multiclass(Y_final,preds_final)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taskB_OORF test final\n",
            "============\n",
            "True labels: [2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1]\n",
            "Pred labels: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Accuracy: 0.5090016366612111\n",
            "Precision: 0.16994535519125684\n",
            "Recall: 0.33226495726495725\n",
            "F1 Macro-avg:0.22487346348517714 \n",
            "\n",
            "\n",
            "taskB_OCRF test final\n",
            "============\n",
            "True labels: [2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1]\n",
            "Pred labels: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Accuracy: 0.5106382978723404\n",
            "Precision: 0.1702127659574468\n",
            "Recall: 0.3333333333333333\n",
            "F1 Macro-avg:0.22535211267605634 \n",
            "\n",
            "\n",
            "taskB_OCGB test final\n",
            "============\n",
            "True labels: [2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1]\n",
            "Pred labels: [2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2]\n",
            "Accuracy: 0.513911620294599\n",
            "Precision: 0.34149009607265923\n",
            "Recall: 0.3516883563114719\n",
            "F1 Macro-avg:0.29300422260360814 \n",
            "\n",
            "\n",
            "taskB_OOCB test final\n",
            "============\n",
            "True labels: [2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1]\n",
            "Pred labels: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Accuracy: 0.5073649754500819\n",
            "Precision: 0.33719646799117003\n",
            "Recall: 0.3334615384615385\n",
            "F1 Macro-avg:0.23142677740674145 \n",
            "\n",
            "\n",
            "multi-outputcode-gradientboost-all test final\n",
            "============\n",
            "True labels: [2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1]\n",
            "Pred labels: [2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2]\n",
            "Accuracy: 0.5090016366612111\n",
            "Precision: 0.424398712986977\n",
            "Recall: 0.35600631361937896\n",
            "F1 Macro-avg:0.2986845666994346 \n",
            "\n",
            "\n",
            "taskB_LSTM test final\n",
            "============\n",
            "611/611 [==============================] - 4s 6ms/step\n",
            "True labels: [2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1]\n",
            "Pred labels: [2, 1, 2, 1, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Accuracy: 0.5400981996726678\n",
            "Precision: 0.4880133514263878\n",
            "Recall: 0.40805501868315935\n",
            "F1 Macro-avg:0.3782696385413426 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWSOv0HbYom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gfkgmpQiFNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}